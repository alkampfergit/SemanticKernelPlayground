{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://alkopenai2.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "print(os.getenv(\"OPENAI_API_BASE\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this example I want a valid logger\n",
    "import logging\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(\"SK\")\n",
    "\n",
    "# Set the logging level to INFO\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create a console handler\n",
    "console_handler = logging.StreamHandler()\n",
    "\n",
    "# Set the level of the console handler to INFO\n",
    "console_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create a formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set the formatter for the console handler\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the console handler to the logger\n",
    "logger.addHandler(console_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using deploy https://alkopenai2.openai.azure.com/ with model gpt42\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureTextCompletion,\n",
    ")\n",
    "\n",
    "model = os.getenv(\"AZURE_GPT4_MODEL\", \"gpt4\")\n",
    "endpoint = os.getenv(\"OPENAI_API_BASE\")\n",
    "kernel = sk.Kernel(log=logger)\n",
    "kernel.add_chat_service(\n",
    "    \"chat_completion\",\n",
    "    AzureChatCompletion(\n",
    "        model,\n",
    "        endpoint = endpoint,\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"Using deploy {endpoint} with model {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 12:01:37,945 - SK - DEBUG - Importing skill AudioVideoPlugin\n",
      "2024-03-27 12:01:37,946 - SK - DEBUG - Methods imported: 2\n",
      "2024-03-27 12:01:37,954 - SK - DEBUG - Extracting blocks from template: I will give you a transcript of a video. You need to summarize the video based on transcript to \n",
      "create a description that can be used in YouTube. I want no more than 500 words. If possible please \n",
      "generate three different description, changing the style of writing.\n",
      "\n",
      "First one should be more professional\n",
      "Second one should be more casual\n",
      "Third one aim to maximize engagement.\n",
      "\n",
      "TRANSCRIPT\n",
      "\"\"\"\n",
      "{{$input}}\n",
      "\"\"\"\n",
      "2024-03-27 12:01:37,959 - SK - DEBUG - Extracting blocks from template: I will give you a transcript of a video. The transcript contains phrases prefixed by the timestamp where the phrase starts. I want you to identify between three and ten main sections of the video. You must never identify more than ten sections.\n",
      "For each section you will create a brief title prefixed with the start timestamp of the section obtained analyzing all the text belonging to that section.\n",
      "\n",
      "EXAMPLE ANSWER - Maximum of ten sections\n",
      "00:00 - Title of section 1\n",
      "00:33 - Title of section 2\n",
      "01:23 - Title of section 3\n",
      "\n",
      "[DATA]\n",
      "{{$input}}\n"
     ]
    }
   ],
   "source": [
    "# Now we need to import the plugin\n",
    "from plugins.AudioVideoPlugin.AudioVideo import AudioVideo\n",
    "\n",
    "# Now you can import the plugin importing skill directly from the function you declared\n",
    "# in the plugin directory. The import_skill does not need the path, it only need an\n",
    "# instance of the skill and the name of the skill\n",
    "extractaudio_plugin = kernel.import_skill(AudioVideo(), skill_name=\"AudioVideoPlugin\")\n",
    "\n",
    "plugins_directory = \"./plugins\"\n",
    "\n",
    "# Import the OrchestratorPlugin from the plugins directory.\n",
    "publishing_plugin = kernel.import_semantic_skill_from_directory(\n",
    "    plugins_directory, \"PublishingPlugin\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<semantic_kernel.orchestration.sk_function.SKFunction object at 0x00000265F56178B0>\n",
      "<semantic_kernel.orchestration.sk_function.SKFunction object at 0x00000265B13AB700>\n",
      "<semantic_kernel.orchestration.sk_function.SKFunction object at 0x00000265B13A9450>\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# want to print all the keys of extractaudio_plugin that is a dictionary\n",
    "\n",
    "pprint (extractaudio_plugin[\"ExtractAudio\"])\n",
    "pprint (extractaudio_plugin[\"TranscriptTimeline\"])\n",
    "pprint (publishing_plugin[\"VideoTimelineCreator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can verify if cuda is available.\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting auio file from video S:\\OneDrive\\Youtube\\AI\\SemanticChain\\MontaggiCompleti\\230 - Kernel Memory and Python.mp4\n",
      "Extracting transcript from audio file S:\\OneDrive\\Youtube\\AI\\SemanticChain\\MontaggiCompleti\\230 - Kernel Memory and Python.wav\n",
      "Using device: cuda:0 to run whisper with model medium.en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 12:01:45,375 - SK - ERROR - Something went wrong in pipeline step 1. During function invocation: 'AudioVideoPlugin.TranscriptTimeline'. Error description: 'Failed to load audio: ffmpeg version 6.0-essentials_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-d3d11va --enable-dxva2 --enable-libvpl --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "S:\\OneDrive\\Youtube\\AI\\SemanticChain\\MontaggiCompleti\\230 - Kernel Memory and Python.wav: No such file or directory\n",
      "'\n"
     ]
    }
   ],
   "source": [
    "# Now we can use the skill\n",
    "# Run the Sqrt function with the context.\n",
    "result = await kernel.run_async(\n",
    "    extractaudio_plugin[\"ExtractAudio\"],\n",
    "    extractaudio_plugin[\"TranscriptTimeline\"],\n",
    "    publishing_plugin[\"VideoTimelineCreator\"],\n",
    "    input_str=\"S:\\\\OneDrive\\\\Youtube\\\\AI\\\\SemanticChain\\\\MontaggiCompleti\\\\230-Kernel_Memory_and_Python.mp4\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Failed to load audio: ffmpeg version 6.0-essentials_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-d3d11va --enable-dxva2 --enable-libvpl --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "S:\\OneDrive\\Youtube\\AI\\SemanticChain\\MontaggiCompleti\\230 - Kernel Memory and Python.wav: No such file or directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
